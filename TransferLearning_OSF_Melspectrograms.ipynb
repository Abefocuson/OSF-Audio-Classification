{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio Event Classifier with Deep Learning\n",
    "\n",
    "Build a CNN sound classifier using melspectograms from OSF data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.utils import multi_gpu_model\n",
    "import numpy as np\n",
    "import json\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 40\n",
    "epochs = 50\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "input_tensor = Input(shape=(224,224,3))\n",
    "\n",
    "nb_training_samples = 3716\n",
    "nb_validation_samples = 1219# Set parameter values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure training and validation data generators\n",
    "\n",
    "Provide paths to training and testing set directores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3716 images belonging to 2 classes.\n",
      "Found 1219 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# training generator configuration\n",
    "training_data_dir = '/Users/xt/Desktop/OSF/melspectrograms/train/'\n",
    "\n",
    "training_datagen = image.ImageDataGenerator(\n",
    "    rescale=1./255)\n",
    "\n",
    "training_generator = training_datagen.flow_from_directory(\n",
    "    training_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "# validation generator configuration\n",
    "validation_data_dir ='/Users/xt/Desktop/OSF/melspectrograms/validation/'\n",
    "\n",
    "validation_datagen = image.ImageDataGenerator(\n",
    "    rescale=1./255)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
    "print('Model loaded.')\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build top model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               6422784   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 6,423,298\n",
      "Trainable params: 6,423,298\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build a classifier model to put on top of the convolutional model\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(2, activation='softmax'))\n",
    "top_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine base model with top model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 2)                 6423298   \n",
      "=================================================================\n",
      "Total params: 21,137,986\n",
      "Trainable params: 21,137,986\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# top_model.load_weights('bootlneck_fc_model.h5')\n",
    "model = Model(inputs=base_model.input, outputs=top_model(base_model.output))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers_to_freeze = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import metrics, optimizers\n",
    "\n",
    "def top_1_accuracy(y_true, y_pred):\n",
    "    return metrics.top_k_categorical_accuracy(y_true, y_pred, k=1)\n",
    "\n",
    "for layer in model.layers[:num_layers_to_freeze]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# use nesterov accelrated gradient descent ??\n",
    "# optimizer=optimizers.SGD(lr=1e-4, momentum=0.9, decay=1e-6, nesterov=True)\n",
    "model.compile(optimizer=optimizers.SGD(lr=1e-4, momentum=0.9), \n",
    "                      loss='categorical_crossentropy', \n",
    "                      metrics=['accuracy', top_1_accuracy])\n",
    "\n",
    "# parallel_model.compile(optimizer=optimizers.SGD(lr=1e-4, momentum=0.9), \n",
    "#                       loss='categorical_crossentropy', \n",
    "#                       metrics=['accuracy', top_1_accuracy])\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "model_filename = \"vgg16_model_{}_frozen_layers.json\".format(num_layers_to_freeze)\n",
    "with open(model_filename, \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-8e097d1fe831>:25: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.6407 - accuracy: 0.6445 - top_1_accuracy: 0.6445WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 807s 9s/step - loss: 0.6407 - accuracy: 0.6445 - top_1_accuracy: 0.6445 - val_loss: 0.5458 - val_accuracy: 0.7383 - val_top_1_accuracy: 0.7383\n",
      "Epoch 2/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.5538 - accuracy: 0.7010 - top_1_accuracy: 0.7010WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 795s 9s/step - loss: 0.5538 - accuracy: 0.7010 - top_1_accuracy: 0.7010 - val_loss: 0.5025 - val_accuracy: 0.7498 - val_top_1_accuracy: 0.7498\n",
      "Epoch 3/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.5201 - accuracy: 0.7330 - top_1_accuracy: 0.7330WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 786s 8s/step - loss: 0.5201 - accuracy: 0.7330 - top_1_accuracy: 0.7330 - val_loss: 0.4698 - val_accuracy: 0.7769 - val_top_1_accuracy: 0.7769\n",
      "Epoch 4/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.5071 - accuracy: 0.7419 - top_1_accuracy: 0.7419WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 783s 8s/step - loss: 0.5071 - accuracy: 0.7419 - top_1_accuracy: 0.7419 - val_loss: 0.4646 - val_accuracy: 0.7760 - val_top_1_accuracy: 0.7760\n",
      "Epoch 5/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.4872 - accuracy: 0.7489 - top_1_accuracy: 0.7489WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 783s 8s/step - loss: 0.4872 - accuracy: 0.7489 - top_1_accuracy: 0.7489 - val_loss: 0.4384 - val_accuracy: 0.8007 - val_top_1_accuracy: 0.8007\n",
      "Epoch 6/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.4761 - accuracy: 0.7597 - top_1_accuracy: 0.7597WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 781s 8s/step - loss: 0.4761 - accuracy: 0.7597 - top_1_accuracy: 0.7597 - val_loss: 0.4261 - val_accuracy: 0.8089 - val_top_1_accuracy: 0.8089\n",
      "Epoch 7/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.4609 - accuracy: 0.7721 - top_1_accuracy: 0.7721WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 780s 8s/step - loss: 0.4609 - accuracy: 0.7721 - top_1_accuracy: 0.7721 - val_loss: 0.4415 - val_accuracy: 0.7785 - val_top_1_accuracy: 0.7785\n",
      "Epoch 8/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.4384 - accuracy: 0.7772 - top_1_accuracy: 0.7772WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 779s 8s/step - loss: 0.4384 - accuracy: 0.7772 - top_1_accuracy: 0.7772 - val_loss: 0.4094 - val_accuracy: 0.8236 - val_top_1_accuracy: 0.8236\n",
      "Epoch 9/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.4313 - accuracy: 0.7882 - top_1_accuracy: 0.7882WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 777s 8s/step - loss: 0.4313 - accuracy: 0.7882 - top_1_accuracy: 0.7882 - val_loss: 0.4056 - val_accuracy: 0.8179 - val_top_1_accuracy: 0.8179\n",
      "Epoch 10/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.4281 - accuracy: 0.7882 - top_1_accuracy: 0.7882WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 774s 8s/step - loss: 0.4281 - accuracy: 0.7882 - top_1_accuracy: 0.7882 - val_loss: 0.3968 - val_accuracy: 0.8285 - val_top_1_accuracy: 0.8285\n",
      "Epoch 11/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.4167 - accuracy: 0.7990 - top_1_accuracy: 0.7990WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 790s 8s/step - loss: 0.4167 - accuracy: 0.7990 - top_1_accuracy: 0.7990 - val_loss: 0.3952 - val_accuracy: 0.8130 - val_top_1_accuracy: 0.8130\n",
      "Epoch 12/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.4037 - accuracy: 0.8057 - top_1_accuracy: 0.8057WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 800s 9s/step - loss: 0.4037 - accuracy: 0.8057 - top_1_accuracy: 0.8057 - val_loss: 0.3846 - val_accuracy: 0.8409 - val_top_1_accuracy: 0.8409\n",
      "Epoch 13/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.4037 - accuracy: 0.8076 - top_1_accuracy: 0.8076WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 809s 9s/step - loss: 0.4037 - accuracy: 0.8076 - top_1_accuracy: 0.8076 - val_loss: 0.3784 - val_accuracy: 0.8376 - val_top_1_accuracy: 0.8376\n",
      "Epoch 14/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.3982 - accuracy: 0.8062 - top_1_accuracy: 0.8062WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 811s 9s/step - loss: 0.3982 - accuracy: 0.8062 - top_1_accuracy: 0.8062 - val_loss: 0.3887 - val_accuracy: 0.8080 - val_top_1_accuracy: 0.8080\n",
      "Epoch 15/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.3859 - accuracy: 0.8135 - top_1_accuracy: 0.8135WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 816s 9s/step - loss: 0.3859 - accuracy: 0.8135 - top_1_accuracy: 0.8135 - val_loss: 0.3699 - val_accuracy: 0.8409 - val_top_1_accuracy: 0.8409\n",
      "Epoch 16/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.3869 - accuracy: 0.8219 - top_1_accuracy: 0.8219WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 817s 9s/step - loss: 0.3869 - accuracy: 0.8219 - top_1_accuracy: 0.8219 - val_loss: 0.3659 - val_accuracy: 0.8458 - val_top_1_accuracy: 0.8458\n",
      "Epoch 17/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.3727 - accuracy: 0.8251 - top_1_accuracy: 0.8251WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 822s 9s/step - loss: 0.3727 - accuracy: 0.8251 - top_1_accuracy: 0.8251 - val_loss: 0.3647 - val_accuracy: 0.8523 - val_top_1_accuracy: 0.8523\n",
      "Epoch 18/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.3743 - accuracy: 0.8253 - top_1_accuracy: 0.8253WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 824s 9s/step - loss: 0.3743 - accuracy: 0.8253 - top_1_accuracy: 0.8253 - val_loss: 0.3776 - val_accuracy: 0.8212 - val_top_1_accuracy: 0.8212\n",
      "Epoch 19/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.3614 - accuracy: 0.8326 - top_1_accuracy: 0.8326WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 823s 9s/step - loss: 0.3614 - accuracy: 0.8326 - top_1_accuracy: 0.8326 - val_loss: 0.3570 - val_accuracy: 0.8450 - val_top_1_accuracy: 0.8450\n",
      "Epoch 20/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.3513 - accuracy: 0.8337 - top_1_accuracy: 0.8337WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 823s 9s/step - loss: 0.3513 - accuracy: 0.8337 - top_1_accuracy: 0.8337 - val_loss: 0.3758 - val_accuracy: 0.8203 - val_top_1_accuracy: 0.8203\n",
      "Epoch 21/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.3506 - accuracy: 0.8353 - top_1_accuracy: 0.8353WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 825s 9s/step - loss: 0.3506 - accuracy: 0.8353 - top_1_accuracy: 0.8353 - val_loss: 0.3561 - val_accuracy: 0.8466 - val_top_1_accuracy: 0.8466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.3530 - accuracy: 0.8326 - top_1_accuracy: 0.8326WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 822s 9s/step - loss: 0.3530 - accuracy: 0.8326 - top_1_accuracy: 0.8326 - val_loss: 0.3547 - val_accuracy: 0.8450 - val_top_1_accuracy: 0.8450\n",
      "Epoch 23/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.3353 - accuracy: 0.8450 - top_1_accuracy: 0.8450WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 796s 9s/step - loss: 0.3353 - accuracy: 0.8450 - top_1_accuracy: 0.8450 - val_loss: 0.3506 - val_accuracy: 0.8507 - val_top_1_accuracy: 0.8507\n",
      "Epoch 24/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.3341 - accuracy: 0.8485 - top_1_accuracy: 0.8485WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 786s 8s/step - loss: 0.3341 - accuracy: 0.8485 - top_1_accuracy: 0.8485 - val_loss: 0.3474 - val_accuracy: 0.8482 - val_top_1_accuracy: 0.8482\n",
      "Epoch 25/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.3277 - accuracy: 0.8544 - top_1_accuracy: 0.8544WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 780s 8s/step - loss: 0.3277 - accuracy: 0.8544 - top_1_accuracy: 0.8544 - val_loss: 0.3445 - val_accuracy: 0.8491 - val_top_1_accuracy: 0.8491\n",
      "Epoch 26/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.3162 - accuracy: 0.8579 - top_1_accuracy: 0.8579WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 774s 8s/step - loss: 0.3162 - accuracy: 0.8579 - top_1_accuracy: 0.8579 - val_loss: 0.3408 - val_accuracy: 0.8441 - val_top_1_accuracy: 0.8441\n",
      "Epoch 27/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.3167 - accuracy: 0.8550 - top_1_accuracy: 0.8550WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 775s 8s/step - loss: 0.3167 - accuracy: 0.8550 - top_1_accuracy: 0.8550 - val_loss: 0.3417 - val_accuracy: 0.8499 - val_top_1_accuracy: 0.8499\n",
      "Epoch 28/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.3204 - accuracy: 0.8509 - top_1_accuracy: 0.8509WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 794s 9s/step - loss: 0.3204 - accuracy: 0.8509 - top_1_accuracy: 0.8509 - val_loss: 0.3423 - val_accuracy: 0.8540 - val_top_1_accuracy: 0.8540\n",
      "Epoch 29/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.3276 - accuracy: 0.8528 - top_1_accuracy: 0.8528WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 806s 9s/step - loss: 0.3276 - accuracy: 0.8528 - top_1_accuracy: 0.8528 - val_loss: 0.3838 - val_accuracy: 0.8162 - val_top_1_accuracy: 0.8162\n",
      "Epoch 30/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.2982 - accuracy: 0.8716 - top_1_accuracy: 0.8716WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 812s 9s/step - loss: 0.2982 - accuracy: 0.8716 - top_1_accuracy: 0.8716 - val_loss: 0.3383 - val_accuracy: 0.8532 - val_top_1_accuracy: 0.8532\n",
      "Epoch 31/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.3029 - accuracy: 0.8641 - top_1_accuracy: 0.8641WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 818s 9s/step - loss: 0.3029 - accuracy: 0.8641 - top_1_accuracy: 0.8641 - val_loss: 0.3574 - val_accuracy: 0.8376 - val_top_1_accuracy: 0.8376\n",
      "Epoch 32/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.2970 - accuracy: 0.8687 - top_1_accuracy: 0.8687WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 818s 9s/step - loss: 0.2970 - accuracy: 0.8687 - top_1_accuracy: 0.8687 - val_loss: 0.3475 - val_accuracy: 0.8441 - val_top_1_accuracy: 0.8441\n",
      "Epoch 33/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.2903 - accuracy: 0.8711 - top_1_accuracy: 0.8711WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 819s 9s/step - loss: 0.2903 - accuracy: 0.8711 - top_1_accuracy: 0.8711 - val_loss: 0.3372 - val_accuracy: 0.8474 - val_top_1_accuracy: 0.8474\n",
      "Epoch 34/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.2885 - accuracy: 0.8695 - top_1_accuracy: 0.8695WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 821s 9s/step - loss: 0.2885 - accuracy: 0.8695 - top_1_accuracy: 0.8695 - val_loss: 0.3462 - val_accuracy: 0.8425 - val_top_1_accuracy: 0.8425\n",
      "Epoch 35/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.2747 - accuracy: 0.8802 - top_1_accuracy: 0.8802WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 825s 9s/step - loss: 0.2747 - accuracy: 0.8802 - top_1_accuracy: 0.8802 - val_loss: 0.3352 - val_accuracy: 0.8540 - val_top_1_accuracy: 0.8540\n",
      "Epoch 36/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.2779 - accuracy: 0.8800 - top_1_accuracy: 0.8800WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 826s 9s/step - loss: 0.2779 - accuracy: 0.8800 - top_1_accuracy: 0.8800 - val_loss: 0.4279 - val_accuracy: 0.8015 - val_top_1_accuracy: 0.8015\n",
      "Epoch 37/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.2749 - accuracy: 0.8832 - top_1_accuracy: 0.8832WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 822s 9s/step - loss: 0.2749 - accuracy: 0.8832 - top_1_accuracy: 0.8832 - val_loss: 0.3406 - val_accuracy: 0.8548 - val_top_1_accuracy: 0.8548\n",
      "Epoch 38/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.2610 - accuracy: 0.8840 - top_1_accuracy: 0.8840WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 791s 9s/step - loss: 0.2610 - accuracy: 0.8840 - top_1_accuracy: 0.8840 - val_loss: 0.3318 - val_accuracy: 0.8614 - val_top_1_accuracy: 0.8614\n",
      "Epoch 39/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.2548 - accuracy: 0.8905 - top_1_accuracy: 0.8905WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 782s 8s/step - loss: 0.2548 - accuracy: 0.8905 - top_1_accuracy: 0.8905 - val_loss: 0.3454 - val_accuracy: 0.8474 - val_top_1_accuracy: 0.8474\n",
      "Epoch 40/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.2586 - accuracy: 0.8846 - top_1_accuracy: 0.8846WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 785s 8s/step - loss: 0.2586 - accuracy: 0.8846 - top_1_accuracy: 0.8846 - val_loss: 0.3490 - val_accuracy: 0.8466 - val_top_1_accuracy: 0.8466\n",
      "Epoch 41/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.2523 - accuracy: 0.8921 - top_1_accuracy: 0.8921WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 779s 8s/step - loss: 0.2523 - accuracy: 0.8921 - top_1_accuracy: 0.8921 - val_loss: 0.3520 - val_accuracy: 0.8482 - val_top_1_accuracy: 0.8482\n",
      "Epoch 42/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.2456 - accuracy: 0.8975 - top_1_accuracy: 0.8975WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 779s 8s/step - loss: 0.2456 - accuracy: 0.8975 - top_1_accuracy: 0.8975 - val_loss: 0.3610 - val_accuracy: 0.8491 - val_top_1_accuracy: 0.8491\n",
      "Epoch 43/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.2409 - accuracy: 0.8972 - top_1_accuracy: 0.8972WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/92 [==============================] - 783s 8s/step - loss: 0.2409 - accuracy: 0.8972 - top_1_accuracy: 0.8972 - val_loss: 0.3353 - val_accuracy: 0.8597 - val_top_1_accuracy: 0.8597\n",
      "Epoch 44/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.2580 - accuracy: 0.8878 - top_1_accuracy: 0.8878WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 784s 8s/step - loss: 0.2580 - accuracy: 0.8878 - top_1_accuracy: 0.8878 - val_loss: 0.4124 - val_accuracy: 0.8130 - val_top_1_accuracy: 0.8130\n",
      "Epoch 45/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.2420 - accuracy: 0.8950 - top_1_accuracy: 0.8950WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 783s 8s/step - loss: 0.2420 - accuracy: 0.8950 - top_1_accuracy: 0.8950 - val_loss: 0.3376 - val_accuracy: 0.8523 - val_top_1_accuracy: 0.8523\n",
      "Epoch 46/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.2266 - accuracy: 0.9053 - top_1_accuracy: 0.9053WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 784s 8s/step - loss: 0.2266 - accuracy: 0.9053 - top_1_accuracy: 0.9053 - val_loss: 0.3519 - val_accuracy: 0.8523 - val_top_1_accuracy: 0.8523\n",
      "Epoch 47/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.2241 - accuracy: 0.9029 - top_1_accuracy: 0.9029WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 788s 8s/step - loss: 0.2241 - accuracy: 0.9029 - top_1_accuracy: 0.9029 - val_loss: 0.3467 - val_accuracy: 0.8532 - val_top_1_accuracy: 0.8532\n",
      "Epoch 48/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.2175 - accuracy: 0.9144 - top_1_accuracy: 0.9144WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 787s 8s/step - loss: 0.2175 - accuracy: 0.9144 - top_1_accuracy: 0.9144 - val_loss: 0.3357 - val_accuracy: 0.8605 - val_top_1_accuracy: 0.8605\n",
      "Epoch 49/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.2109 - accuracy: 0.9096 - top_1_accuracy: 0.9096WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 788s 8s/step - loss: 0.2109 - accuracy: 0.9096 - top_1_accuracy: 0.9096 - val_loss: 0.3399 - val_accuracy: 0.8556 - val_top_1_accuracy: 0.8556\n",
      "Epoch 50/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.2019 - accuracy: 0.9209 - top_1_accuracy: 0.9209WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 783s 8s/step - loss: 0.2019 - accuracy: 0.9209 - top_1_accuracy: 0.9209 - val_loss: 0.3499 - val_accuracy: 0.8556 - val_top_1_accuracy: 0.8556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe06420cd10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from time import time\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs/layers_frozen_{}\".format(num_layers_to_freeze))\n",
    "\n",
    "# checkpoint\n",
    "filepath=\"esc50_vgg16_stft_weights_train_last_2_base_layers.best.hdf5\"\n",
    "best_model_checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [best_model_checkpoint, tensorboard]\n",
    "\n",
    "# parallel_model.fit_generator(\n",
    "#     training_generator,\n",
    "#     steps_per_epoch=nb_training_samples/batch_size,\n",
    "#     epochs=epochs,\n",
    "#     validation_data=validation_generator,\n",
    "#     validation_steps=nb_validation_samples/batch_size,\n",
    "#     callbacks=callbacks_list)\n",
    "\n",
    "model.fit_generator(\n",
    "    training_generator,\n",
    "    steps_per_epoch=nb_training_samples/batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples/batch_size,\n",
    "    callbacks=callbacks_list)\n",
    "# parallel_model.fit_generator(\n",
    "#     training_generator,\n",
    "#     samples_per_epoch=nb_training_samples,\n",
    "#     epochs=epochs,\n",
    "#     validation_data=validation_generator,\n",
    "#     validation_steps=nb_validation_samples/batch_size,)\n",
    "#     nb_val_samples=nb_validation_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get top k predictions for selected test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k_predictions(preds, label_map, k=1, print_flag=False):\n",
    "    sorted_array = np.argsort(preds)[::-1]\n",
    "    top_k = sorted_array[:k]\n",
    "    label_map_flip = dict((v,k) for k,v in label_map.items())\n",
    "    \n",
    "    y_pred = []\n",
    "    for label_index in top_k:\n",
    "        if print_flag:\n",
    "            print (\"{} ({})\".format(label_map_flip[label_index], preds[label_index]))\n",
    "        y_pred.append(label_map_flip[label_index])\n",
    "        \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['not_sick', 'sick']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map = (training_generator.class_indices)\n",
    " \n",
    "json2 = json.dumps(label_map)\n",
    "f = open(\"cough_label_map.json\",\"w\")\n",
    "f.write(json2)\n",
    "f.close()\n",
    "\n",
    "img_path = '/Users/xt/Desktop/OSF/melspectrograms/test/sick/audioset__3RvCwwIZ4w_10_15.png'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)* 1./255\n",
    "\n",
    "preds = model.predict(x)[0]\n",
    "\n",
    "get_top_k_predictions(preds, label_map, k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate and plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "#     print(cm)\n",
    "    plt.figure(figsize=(24,24))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x1728 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import requests\n",
    "import urllib.request\n",
    "from PIL import Image\n",
    "from keras.preprocessing import image\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "testing_dir = '/Users/xt/Desktop/OSF/melspectrograms/test/'\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for label in label_map.keys():\n",
    "    file_list = os.listdir(testing_dir + label)\n",
    "    for file_name in file_list:\n",
    "        if file_name != '.DS_Store':\n",
    "            img_path = testing_dir + label + '/' + file_name\n",
    "            img = image.load_img(img_path, target_size=(224, 224))\n",
    "            \n",
    "            x = image.img_to_array(img)\n",
    "            x = np.expand_dims(x, axis=0)* 1./255\n",
    "            \n",
    "            preds = model.predict(x)[0]\n",
    "            \n",
    "            y_true.append(label)\n",
    "            y_pred.append(get_top_k_predictions(preds, label_map, k=1)[0])\n",
    "        \n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plot_confusion_matrix(cm, sorted(label_map.keys()), normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
