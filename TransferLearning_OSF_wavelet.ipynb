{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio Event Classifier with Deep Learning\n",
    "\n",
    "Build a CNN sound classifier using continuous_wavelet_transform from OSF data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.utils import multi_gpu_model\n",
    "import numpy as np\n",
    "import json\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 40\n",
    "epochs = 50\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "input_tensor = Input(shape=(224,224,3))\n",
    "\n",
    "nb_training_samples = 3716\n",
    "nb_validation_samples = 1219# Set parameter values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure training and validation data generators\n",
    "\n",
    "Provide paths to training and testing set directores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3716 images belonging to 2 classes.\n",
      "Found 1219 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# training generator configuration\n",
    "training_data_dir = '/Users/xt/Desktop/OSF/continuous_wavelet_transform/train/'\n",
    "\n",
    "training_datagen = image.ImageDataGenerator(\n",
    "    rescale=1./255)\n",
    "\n",
    "training_generator = training_datagen.flow_from_directory(\n",
    "    training_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "# validation generator configuration\n",
    "validation_data_dir ='/Users/xt/Desktop/OSF/continuous_wavelet_transform/validation/'\n",
    "\n",
    "validation_datagen = image.ImageDataGenerator(\n",
    "    rescale=1./255)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
    "print('Model loaded.')\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build top model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               6422784   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 6,423,298\n",
      "Trainable params: 6,423,298\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build a classifier model to put on top of the convolutional model\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(2, activation='softmax'))\n",
    "top_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine base model with top model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 2)                 6423298   \n",
      "=================================================================\n",
      "Total params: 21,137,986\n",
      "Trainable params: 21,137,986\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# top_model.load_weights('bootlneck_fc_model.h5')\n",
    "model = Model(inputs=base_model.input, outputs=top_model(base_model.output))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers_to_freeze = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import metrics, optimizers\n",
    "\n",
    "def top_1_accuracy(y_true, y_pred):\n",
    "    return metrics.top_k_categorical_accuracy(y_true, y_pred, k=1)\n",
    "\n",
    "for layer in model.layers[:num_layers_to_freeze]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# use nesterov accelrated gradient descent ??\n",
    "# optimizer=optimizers.SGD(lr=1e-4, momentum=0.9, decay=1e-6, nesterov=True)\n",
    "model.compile(optimizer=optimizers.SGD(lr=1e-4, momentum=0.9), \n",
    "                      loss='categorical_crossentropy', \n",
    "                      metrics=['accuracy', top_1_accuracy])\n",
    "\n",
    "# parallel_model.compile(optimizer=optimizers.SGD(lr=1e-4, momentum=0.9), \n",
    "#                       loss='categorical_crossentropy', \n",
    "#                       metrics=['accuracy', top_1_accuracy])\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "model_filename = \"vgg16_model_{}_frozen_layers.json\".format(num_layers_to_freeze)\n",
    "with open(model_filename, \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-8e097d1fe831>:25: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.6581 - accuracy: 0.6136 - top_1_accuracy: 0.6136WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 781s 8s/step - loss: 0.6581 - accuracy: 0.6136 - top_1_accuracy: 0.6136 - val_loss: 0.5500 - val_accuracy: 0.7441 - val_top_1_accuracy: 0.7441\n",
      "Epoch 2/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.5551 - accuracy: 0.7040 - top_1_accuracy: 0.7040WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 775s 8s/step - loss: 0.5551 - accuracy: 0.7040 - top_1_accuracy: 0.7040 - val_loss: 0.5153 - val_accuracy: 0.7260 - val_top_1_accuracy: 0.7260\n",
      "Epoch 3/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.5123 - accuracy: 0.7365 - top_1_accuracy: 0.7365WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 777s 8s/step - loss: 0.5123 - accuracy: 0.7365 - top_1_accuracy: 0.7365 - val_loss: 0.4721 - val_accuracy: 0.7605 - val_top_1_accuracy: 0.7605\n",
      "Epoch 4/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.4862 - accuracy: 0.7497 - top_1_accuracy: 0.7497WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 780s 8s/step - loss: 0.4862 - accuracy: 0.7497 - top_1_accuracy: 0.7497 - val_loss: 0.4565 - val_accuracy: 0.7884 - val_top_1_accuracy: 0.7884\n",
      "Epoch 5/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.4724 - accuracy: 0.7675 - top_1_accuracy: 0.7675WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 781s 8s/step - loss: 0.4724 - accuracy: 0.7675 - top_1_accuracy: 0.7675 - val_loss: 0.4455 - val_accuracy: 0.7892 - val_top_1_accuracy: 0.7892\n",
      "Epoch 6/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.4491 - accuracy: 0.7812 - top_1_accuracy: 0.7812WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 786s 8s/step - loss: 0.4491 - accuracy: 0.7812 - top_1_accuracy: 0.7812 - val_loss: 0.4360 - val_accuracy: 0.7990 - val_top_1_accuracy: 0.7990\n",
      "Epoch 7/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.4326 - accuracy: 0.7896 - top_1_accuracy: 0.7896WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 783s 8s/step - loss: 0.4326 - accuracy: 0.7896 - top_1_accuracy: 0.7896 - val_loss: 0.4412 - val_accuracy: 0.7801 - val_top_1_accuracy: 0.7801\n",
      "Epoch 8/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.4266 - accuracy: 0.7957 - top_1_accuracy: 0.7957WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 780s 8s/step - loss: 0.4266 - accuracy: 0.7957 - top_1_accuracy: 0.7957 - val_loss: 0.4137 - val_accuracy: 0.8023 - val_top_1_accuracy: 0.8023\n",
      "Epoch 9/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.4068 - accuracy: 0.8041 - top_1_accuracy: 0.8041WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 779s 8s/step - loss: 0.4068 - accuracy: 0.8041 - top_1_accuracy: 0.8041 - val_loss: 0.4077 - val_accuracy: 0.8105 - val_top_1_accuracy: 0.8105\n",
      "Epoch 10/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.4034 - accuracy: 0.8122 - top_1_accuracy: 0.8122WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 779s 8s/step - loss: 0.4034 - accuracy: 0.8122 - top_1_accuracy: 0.8122 - val_loss: 0.4056 - val_accuracy: 0.8130 - val_top_1_accuracy: 0.8130\n",
      "Epoch 11/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.3951 - accuracy: 0.8089 - top_1_accuracy: 0.8089WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 778s 8s/step - loss: 0.3951 - accuracy: 0.8089 - top_1_accuracy: 0.8089 - val_loss: 0.4108 - val_accuracy: 0.8015 - val_top_1_accuracy: 0.8015\n",
      "Epoch 12/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.3856 - accuracy: 0.8243 - top_1_accuracy: 0.8243WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 777s 8s/step - loss: 0.3856 - accuracy: 0.8243 - top_1_accuracy: 0.8243 - val_loss: 0.4064 - val_accuracy: 0.8187 - val_top_1_accuracy: 0.8187\n",
      "Epoch 13/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.3783 - accuracy: 0.8210 - top_1_accuracy: 0.8210WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 776s 8s/step - loss: 0.3783 - accuracy: 0.8210 - top_1_accuracy: 0.8210 - val_loss: 0.3906 - val_accuracy: 0.8130 - val_top_1_accuracy: 0.8130\n",
      "Epoch 14/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.3662 - accuracy: 0.8259 - top_1_accuracy: 0.8259WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 778s 8s/step - loss: 0.3662 - accuracy: 0.8259 - top_1_accuracy: 0.8259 - val_loss: 0.3862 - val_accuracy: 0.8302 - val_top_1_accuracy: 0.8302\n",
      "Epoch 15/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.3609 - accuracy: 0.8302 - top_1_accuracy: 0.8302WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 775s 8s/step - loss: 0.3609 - accuracy: 0.8302 - top_1_accuracy: 0.8302 - val_loss: 0.3799 - val_accuracy: 0.8261 - val_top_1_accuracy: 0.8261\n",
      "Epoch 16/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.3544 - accuracy: 0.8340 - top_1_accuracy: 0.8340WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 775s 8s/step - loss: 0.3544 - accuracy: 0.8340 - top_1_accuracy: 0.8340 - val_loss: 0.3781 - val_accuracy: 0.8253 - val_top_1_accuracy: 0.8253\n",
      "Epoch 17/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.3454 - accuracy: 0.8353 - top_1_accuracy: 0.8353WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 764s 8s/step - loss: 0.3454 - accuracy: 0.8353 - top_1_accuracy: 0.8353 - val_loss: 0.4307 - val_accuracy: 0.7900 - val_top_1_accuracy: 0.7900\n",
      "Epoch 18/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.3477 - accuracy: 0.8391 - top_1_accuracy: 0.8391WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 775s 8s/step - loss: 0.3477 - accuracy: 0.8391 - top_1_accuracy: 0.8391 - val_loss: 0.3703 - val_accuracy: 0.8285 - val_top_1_accuracy: 0.8285\n",
      "Epoch 19/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.3297 - accuracy: 0.8455 - top_1_accuracy: 0.8455WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 788s 8s/step - loss: 0.3297 - accuracy: 0.8455 - top_1_accuracy: 0.8455 - val_loss: 0.3804 - val_accuracy: 0.8244 - val_top_1_accuracy: 0.8244\n",
      "Epoch 20/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.3272 - accuracy: 0.8453 - top_1_accuracy: 0.8453WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 799s 9s/step - loss: 0.3272 - accuracy: 0.8453 - top_1_accuracy: 0.8453 - val_loss: 0.3837 - val_accuracy: 0.8244 - val_top_1_accuracy: 0.8244\n",
      "Epoch 21/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.3206 - accuracy: 0.8525 - top_1_accuracy: 0.8525WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 802s 9s/step - loss: 0.3206 - accuracy: 0.8525 - top_1_accuracy: 0.8525 - val_loss: 0.3811 - val_accuracy: 0.8253 - val_top_1_accuracy: 0.8253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.3217 - accuracy: 0.8477 - top_1_accuracy: 0.8477WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 805s 9s/step - loss: 0.3217 - accuracy: 0.8477 - top_1_accuracy: 0.8477 - val_loss: 0.4062 - val_accuracy: 0.8080 - val_top_1_accuracy: 0.8080\n",
      "Epoch 23/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.3135 - accuracy: 0.8636 - top_1_accuracy: 0.8636WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 788s 8s/step - loss: 0.3135 - accuracy: 0.8636 - top_1_accuracy: 0.8636 - val_loss: 0.3698 - val_accuracy: 0.8318 - val_top_1_accuracy: 0.8318\n",
      "Epoch 24/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.3006 - accuracy: 0.8679 - top_1_accuracy: 0.8679WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 779s 8s/step - loss: 0.3006 - accuracy: 0.8679 - top_1_accuracy: 0.8679 - val_loss: 0.3615 - val_accuracy: 0.8409 - val_top_1_accuracy: 0.8409\n",
      "Epoch 25/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.3005 - accuracy: 0.8625 - top_1_accuracy: 0.8625WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 776s 8s/step - loss: 0.3005 - accuracy: 0.8625 - top_1_accuracy: 0.8625 - val_loss: 0.3706 - val_accuracy: 0.8343 - val_top_1_accuracy: 0.8343\n",
      "Epoch 26/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.3027 - accuracy: 0.8654 - top_1_accuracy: 0.8654WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 775s 8s/step - loss: 0.3027 - accuracy: 0.8654 - top_1_accuracy: 0.8654 - val_loss: 0.3594 - val_accuracy: 0.8359 - val_top_1_accuracy: 0.8359\n",
      "Epoch 27/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.3020 - accuracy: 0.8681 - top_1_accuracy: 0.8681WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 825s 9s/step - loss: 0.3020 - accuracy: 0.8681 - top_1_accuracy: 0.8681 - val_loss: 0.3621 - val_accuracy: 0.8409 - val_top_1_accuracy: 0.8409\n",
      "Epoch 28/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.2948 - accuracy: 0.8681 - top_1_accuracy: 0.8681WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 784s 8s/step - loss: 0.2948 - accuracy: 0.8681 - top_1_accuracy: 0.8681 - val_loss: 0.3581 - val_accuracy: 0.8441 - val_top_1_accuracy: 0.8441\n",
      "Epoch 29/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.2887 - accuracy: 0.8735 - top_1_accuracy: 0.8735WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 778s 8s/step - loss: 0.2887 - accuracy: 0.8735 - top_1_accuracy: 0.8735 - val_loss: 0.3538 - val_accuracy: 0.8425 - val_top_1_accuracy: 0.8425\n",
      "Epoch 30/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.2776 - accuracy: 0.8759 - top_1_accuracy: 0.8759WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 790s 8s/step - loss: 0.2776 - accuracy: 0.8759 - top_1_accuracy: 0.8759 - val_loss: 0.3504 - val_accuracy: 0.8450 - val_top_1_accuracy: 0.8450\n",
      "Epoch 31/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.2803 - accuracy: 0.8741 - top_1_accuracy: 0.8741WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 799s 9s/step - loss: 0.2803 - accuracy: 0.8741 - top_1_accuracy: 0.8741 - val_loss: 0.3478 - val_accuracy: 0.8474 - val_top_1_accuracy: 0.8474\n",
      "Epoch 32/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.2775 - accuracy: 0.8789 - top_1_accuracy: 0.8789WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 804s 9s/step - loss: 0.2775 - accuracy: 0.8789 - top_1_accuracy: 0.8789 - val_loss: 0.3503 - val_accuracy: 0.8474 - val_top_1_accuracy: 0.8474\n",
      "Epoch 33/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.2694 - accuracy: 0.8805 - top_1_accuracy: 0.8805WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 803s 9s/step - loss: 0.2694 - accuracy: 0.8805 - top_1_accuracy: 0.8805 - val_loss: 0.3563 - val_accuracy: 0.8441 - val_top_1_accuracy: 0.8441\n",
      "Epoch 34/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.2616 - accuracy: 0.8864 - top_1_accuracy: 0.8864WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 807s 9s/step - loss: 0.2616 - accuracy: 0.8864 - top_1_accuracy: 0.8864 - val_loss: 0.3539 - val_accuracy: 0.8458 - val_top_1_accuracy: 0.8458\n",
      "Epoch 35/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.2600 - accuracy: 0.8891 - top_1_accuracy: 0.8891WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 802s 9s/step - loss: 0.2600 - accuracy: 0.8891 - top_1_accuracy: 0.8891 - val_loss: 0.3560 - val_accuracy: 0.8466 - val_top_1_accuracy: 0.8466\n",
      "Epoch 36/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.2513 - accuracy: 0.8916 - top_1_accuracy: 0.8916WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 786s 8s/step - loss: 0.2513 - accuracy: 0.8916 - top_1_accuracy: 0.8916 - val_loss: 0.3599 - val_accuracy: 0.8482 - val_top_1_accuracy: 0.8482\n",
      "Epoch 37/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.2455 - accuracy: 0.8961 - top_1_accuracy: 0.8961WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 780s 8s/step - loss: 0.2455 - accuracy: 0.8961 - top_1_accuracy: 0.8961 - val_loss: 0.3573 - val_accuracy: 0.8507 - val_top_1_accuracy: 0.8507\n",
      "Epoch 38/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.2524 - accuracy: 0.8934 - top_1_accuracy: 0.8934WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 780s 8s/step - loss: 0.2524 - accuracy: 0.8934 - top_1_accuracy: 0.8934 - val_loss: 0.3570 - val_accuracy: 0.8458 - val_top_1_accuracy: 0.8458\n",
      "Epoch 39/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.2403 - accuracy: 0.8964 - top_1_accuracy: 0.8964WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 778s 8s/step - loss: 0.2403 - accuracy: 0.8964 - top_1_accuracy: 0.8964 - val_loss: 0.3775 - val_accuracy: 0.8409 - val_top_1_accuracy: 0.8409\n",
      "Epoch 40/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.2593 - accuracy: 0.8854 - top_1_accuracy: 0.8854WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 778s 8s/step - loss: 0.2593 - accuracy: 0.8854 - top_1_accuracy: 0.8854 - val_loss: 0.3607 - val_accuracy: 0.8326 - val_top_1_accuracy: 0.8326\n",
      "Epoch 41/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.2417 - accuracy: 0.8953 - top_1_accuracy: 0.8953WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 776s 8s/step - loss: 0.2417 - accuracy: 0.8953 - top_1_accuracy: 0.8953 - val_loss: 0.3477 - val_accuracy: 0.8515 - val_top_1_accuracy: 0.8515\n",
      "Epoch 42/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.2428 - accuracy: 0.8956 - top_1_accuracy: 0.8956WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 776s 8s/step - loss: 0.2428 - accuracy: 0.8956 - top_1_accuracy: 0.8956 - val_loss: 0.3513 - val_accuracy: 0.8556 - val_top_1_accuracy: 0.8556\n",
      "Epoch 43/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.2333 - accuracy: 0.9037 - top_1_accuracy: 0.9037WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/92 [==============================] - 777s 8s/step - loss: 0.2333 - accuracy: 0.9037 - top_1_accuracy: 0.9037 - val_loss: 0.3584 - val_accuracy: 0.8450 - val_top_1_accuracy: 0.8450\n",
      "Epoch 44/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.2367 - accuracy: 0.8967 - top_1_accuracy: 0.8967WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 782s 8s/step - loss: 0.2367 - accuracy: 0.8967 - top_1_accuracy: 0.8967 - val_loss: 0.3490 - val_accuracy: 0.8515 - val_top_1_accuracy: 0.8515\n",
      "Epoch 45/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.2160 - accuracy: 0.9117 - top_1_accuracy: 0.9117WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 796s 9s/step - loss: 0.2160 - accuracy: 0.9117 - top_1_accuracy: 0.9117 - val_loss: 0.3517 - val_accuracy: 0.8564 - val_top_1_accuracy: 0.8564\n",
      "Epoch 46/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.2152 - accuracy: 0.9136 - top_1_accuracy: 0.9136WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 814s 9s/step - loss: 0.2152 - accuracy: 0.9136 - top_1_accuracy: 0.9136 - val_loss: 0.3521 - val_accuracy: 0.8532 - val_top_1_accuracy: 0.8532\n",
      "Epoch 47/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.2062 - accuracy: 0.9179 - top_1_accuracy: 0.9179WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 805s 9s/step - loss: 0.2062 - accuracy: 0.9179 - top_1_accuracy: 0.9179 - val_loss: 0.4146 - val_accuracy: 0.8097 - val_top_1_accuracy: 0.8097\n",
      "Epoch 48/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.2122 - accuracy: 0.9093 - top_1_accuracy: 0.9093WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 806s 9s/step - loss: 0.2122 - accuracy: 0.9093 - top_1_accuracy: 0.9093 - val_loss: 0.3560 - val_accuracy: 0.8548 - val_top_1_accuracy: 0.8548\n",
      "Epoch 49/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.2068 - accuracy: 0.9152 - top_1_accuracy: 0.9152WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 810s 9s/step - loss: 0.2068 - accuracy: 0.9152 - top_1_accuracy: 0.9152 - val_loss: 0.3631 - val_accuracy: 0.8441 - val_top_1_accuracy: 0.8441\n",
      "Epoch 50/50\n",
      "93/92 [==============================] - ETA: 0s - loss: 0.1930 - accuracy: 0.9233 - top_1_accuracy: 0.9233WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "93/92 [==============================] - 809s 9s/step - loss: 0.1930 - accuracy: 0.9233 - top_1_accuracy: 0.9233 - val_loss: 0.3811 - val_accuracy: 0.8491 - val_top_1_accuracy: 0.8491\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa5f10ef090>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from time import time\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs/layers_frozen_{}\".format(num_layers_to_freeze))\n",
    "\n",
    "# checkpoint\n",
    "filepath=\"esc50_vgg16_stft_weights_train_last_2_base_layers.best.hdf5\"\n",
    "best_model_checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [best_model_checkpoint, tensorboard]\n",
    "\n",
    "# parallel_model.fit_generator(\n",
    "#     training_generator,\n",
    "#     steps_per_epoch=nb_training_samples/batch_size,\n",
    "#     epochs=epochs,\n",
    "#     validation_data=validation_generator,\n",
    "#     validation_steps=nb_validation_samples/batch_size,\n",
    "#     callbacks=callbacks_list)\n",
    "\n",
    "model.fit_generator(\n",
    "    training_generator,\n",
    "    steps_per_epoch=nb_training_samples/batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples/batch_size,\n",
    "    callbacks=callbacks_list)\n",
    "# parallel_model.fit_generator(\n",
    "#     training_generator,\n",
    "#     samples_per_epoch=nb_training_samples,\n",
    "#     epochs=epochs,\n",
    "#     validation_data=validation_generator,\n",
    "#     validation_steps=nb_validation_samples/batch_size,)\n",
    "#     nb_val_samples=nb_validation_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get top k predictions for selected test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k_predictions(preds, label_map, k=1, print_flag=False):\n",
    "    sorted_array = np.argsort(preds)[::-1]\n",
    "    top_k = sorted_array[:k]\n",
    "    label_map_flip = dict((v,k) for k,v in label_map.items())\n",
    "    \n",
    "    y_pred = []\n",
    "    for label_index in top_k:\n",
    "        if print_flag:\n",
    "            print (\"{} ({})\".format(label_map_flip[label_index], preds[label_index]))\n",
    "        y_pred.append(label_map_flip[label_index])\n",
    "        \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sick', 'not_sick']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map = (training_generator.class_indices)\n",
    " \n",
    "json2 = json.dumps(label_map)\n",
    "f = open(\"cough_label_map.json\",\"w\")\n",
    "f.write(json2)\n",
    "f.close()\n",
    "\n",
    "img_path = '/Users/xt/Desktop/OSF/continuous_wavelet_transform/test/sick/audioset__3RvCwwIZ4w_10_15.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)* 1./255\n",
    "\n",
    "preds = model.predict(x)[0]\n",
    "\n",
    "get_top_k_predictions(preds, label_map, k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate and plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "#     print(cm)\n",
    "    plt.figure(figsize=(24,24))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x1728 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import requests\n",
    "import urllib.request\n",
    "from PIL import Image\n",
    "from keras.preprocessing import image\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "testing_dir = '/Users/xt/Desktop/OSF/continuous_wavelet_transform/test/'\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for label in label_map.keys():\n",
    "    file_list = os.listdir(testing_dir + label)\n",
    "    for file_name in file_list:\n",
    "        if file_name != '.DS_Store':\n",
    "            img_path = testing_dir + label + '/' + file_name\n",
    "            img = image.load_img(img_path, target_size=(224, 224))\n",
    "            \n",
    "            x = image.img_to_array(img)\n",
    "            x = np.expand_dims(x, axis=0)* 1./255\n",
    "            \n",
    "            preds = model.predict(x)[0]\n",
    "            \n",
    "            y_true.append(label)\n",
    "            y_pred.append(get_top_k_predictions(preds, label_map, k=1)[0])\n",
    "        \n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plot_confusion_matrix(cm, sorted(label_map.keys()), normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
